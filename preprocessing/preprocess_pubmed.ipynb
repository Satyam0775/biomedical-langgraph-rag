{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a2f0a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 1252\n",
      "Requirement already satisfied: pandas in c:\\users\\satya\\anaconda3\\envs\\myenv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\satya\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2.2.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\satya\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\satya\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\satya\\anaconda3\\envs\\myenv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\satya\\anaconda3\\envs\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77da0829",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "760344fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_PATH = r\"C:\\Users\\satya\\Downloads\\biomedical-langgraph-rag\\task\\data\\raw\\pubmed_abstracts.csv\"\n",
    "OUTPUT_PATH = r\"C:\\Users\\satya\\Downloads\\biomedical-langgraph-rag\\task\\data\\processed\\cleaned_pubmed.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db6aaa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (13200, 17)\n",
      "Columns in dataset:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'deep_learning', 'covid_19', 'human_connectome',\n",
       "       'virtual_reality', 'brain_machine_interfaces', 'electroactive_polymers',\n",
       "       'pedot_electrodes', 'neuroprosthetics', 'deep_learning_links',\n",
       "       'covid_19_links', 'human_connectome_links', 'virtual_reality_links',\n",
       "       'brain_machine_interfaces_links', 'electroactive_polymers_links',\n",
       "       'pedot_electrodes_links', 'neuroprosthetics_links'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(RAW_PATH)\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns in dataset:\")\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d50fd72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text columns:\n",
      "['deep_learning', 'covid_19', 'human_connectome', 'virtual_reality', 'brain_machine_interfaces', 'electroactive_polymers', 'pedot_electrodes', 'neuroprosthetics']\n",
      "\n",
      "Link columns (will be dropped):\n",
      "['deep_learning_links', 'covid_19_links', 'human_connectome_links', 'virtual_reality_links', 'brain_machine_interfaces_links', 'electroactive_polymers_links', 'pedot_electrodes_links', 'neuroprosthetics_links']\n"
     ]
    }
   ],
   "source": [
    "text_columns = [col for col in df.columns if not col.endswith(\"_links\") and col != \"Unnamed: 0\"]\n",
    "link_columns = [col for col in df.columns if col.endswith(\"_links\")]\n",
    "\n",
    "print(\"Text columns:\")\n",
    "print(text_columns)\n",
    "\n",
    "print(\"\\nLink columns (will be dropped):\")\n",
    "print(link_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d554f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Magnetic resonance spectroscopic imaging (MRSI...\n",
       "1    Existing deep convolutional neural networks (C...\n",
       "2    Deep learning techniques have been increasingl...\n",
       "3    The original article unfortunately contained a...\n",
       "4    The most common applications of artificial int...\n",
       "Name: combined_text, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def normalize_text_value(value):\n",
    "    \"\"\"\n",
    "    FINAL robust normalizer for this dataset.\n",
    "    Handles stringified tuple(list(text)), list, tuple, NaN.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return \"\"\n",
    "\n",
    "    # Step 1: If already list or tuple\n",
    "    if isinstance(value, (list, tuple)):\n",
    "        value = value[0] if len(value) > 0 else \"\"\n",
    "\n",
    "    # Step 2: If value is string\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()\n",
    "\n",
    "        # Try parsing string into Python object\n",
    "        try:\n",
    "            parsed = ast.literal_eval(value)\n",
    "\n",
    "            # If parsed is tuple -> unwrap\n",
    "            if isinstance(parsed, tuple):\n",
    "                parsed = parsed[0] if len(parsed) > 0 else \"\"\n",
    "\n",
    "            # If parsed is list -> join\n",
    "            if isinstance(parsed, list):\n",
    "                return \" \".join(str(v) for v in parsed)\n",
    "\n",
    "            # If parsed is string\n",
    "            if isinstance(parsed, str):\n",
    "                return parsed\n",
    "\n",
    "        except Exception:\n",
    "            # If parsing fails, return raw string\n",
    "            return value\n",
    "\n",
    "    return str(value)\n",
    "\n",
    "\n",
    "def combine_text(row):\n",
    "    texts = []\n",
    "    for col in text_columns:\n",
    "        cleaned = normalize_text_value(row[col])\n",
    "        if cleaned.strip():\n",
    "            texts.append(cleaned)\n",
    "    return \" \".join(texts)\n",
    "\n",
    "\n",
    "df[\"combined_text\"] = df.apply(combine_text, axis=1)\n",
    "\n",
    "df[\"combined_text\"].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0c6da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    return (\n",
    "        str(text)\n",
    "        .replace(\"\\n\", \" \")\n",
    "        .replace(\"\\t\", \" \")\n",
    "        .strip()\n",
    "    )\n",
    "\n",
    "df[\"clean_text\"] = df[\"combined_text\"].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43adc717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows after cleaning: (13153, 19)\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"clean_text\"].str.len() > 50]\n",
    "print(\"Rows after cleaning:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78ac097b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (13153, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Magnetic resonance spectroscopic imaging (MRSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Existing deep convolutional neural networks (C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Deep learning techniques have been increasingl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The original article unfortunately contained a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The most common applications of artificial int...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  Magnetic resonance spectroscopic imaging (MRSI...\n",
       "1  Existing deep convolutional neural networks (C...\n",
       "2  Deep learning techniques have been increasingl...\n",
       "3  The original article unfortunately contained a...\n",
       "4  The most common applications of artificial int..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df = df[[\"clean_text\"]].rename(columns={\"clean_text\": \"text\"})\n",
    "\n",
    "print(\"Final dataset shape:\", final_df.shape)\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef89af26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned PubMed dataset saved successfully\n"
     ]
    }
   ],
   "source": [
    "final_df.to_csv(\n",
    "    r\"C:\\Users\\satya\\Downloads\\biomedical-langgraph-rag\\task\\data\\processed\\cleaned_pubmed.csv\",\n",
    "    index=False\n",
    ")\n",
    "\n",
    "print(\"✅ Cleaned PubMed dataset saved successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eb51db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
